[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biology 305: Biostatistics",
    "section": "",
    "text": "Preface\nWelcome to Biology 105 at the University of Nebraska at Kearney! Material in this class was designed by Dr. Melissa Wuellner and adapted by Dr. Jacob C. Cooper for use in R.\nIn this class, you will learn:\n\nThe basics of study design, the importance of understanding your research situation before embarking on a full study, and practice creating research frameworks based on different scenarios.\nThe basics of data analysis, including understanding what kind of variables are being collected, why understanding variable types are important, and basic tests to understand univariate distributions.\nBasic multivariate statistics, including ANOVA, correlation, and regression, for comparing multiple different groups.\nThe basics of coding and working in R for performing statistical analyses.\n\nThis site will help you navigate different homework assignments to perform the necessary R tests. Furthermore, this GitHub repository contains all of the homework dataframes, so you will not have to manually enter assignments if you use R to complete your assignments.\nWelcome to class!\nDr. Jacob C. Cooper, BHS 321",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro_to_r.html",
    "href": "intro_to_r.html",
    "title": "1  Intro to R",
    "section": "",
    "text": "2 Setup\nFirst, we need to download R onto your machine. We are also going to download RStudio to assist with creating R scripts and documents.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#installing-r",
    "href": "intro_to_r.html#installing-r",
    "title": "1  Intro to R",
    "section": "2.1 Installing R",
    "text": "2.1 Installing R\nFirst, navigate to the R download and install page. Download the appropriate version for your operating system (Windows, Mac, or Linux). Note that coding will be formatted slightly different for Windows than for other operating systems.\nFollow the installation steps for R, and verify that the installation was successful by searching for R on your machine. You should be presented with a coding window that looks like the following:\nR version 4.4.1 (2024-06-14) -- \"Race for Your Life\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: aarch64-apple-darwin20\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt;\nIf that screen appears, congratulations! R is properly installed. If the install was not successful, please talk to Dr. Cooper and check with your classmates as well.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#installing-rstudio",
    "href": "intro_to_r.html#installing-rstudio",
    "title": "1  Intro to R",
    "section": "2.2 Installing RStudio",
    "text": "2.2 Installing RStudio\nRStudio is a GUI (graphics user interface) that helps make R easier to use. Furthermore, it allows you to create documents in R, including websites (such as this one), PDFs, and even presentations. This can greatly streamline the research pipeline and help you publish your results and associated code in a quick and efficient fashion.\nHead over the the RStudio download website and download “RStudio Desktop”, which is free. Be sure to pick the correct version for your machine.\nOpen RStudio on your machine. You should be presented with something like the following:\n\n\n\nRStudio start window. Note that the screen is split into four different quadrants. Top left: R documents; bottom left: R program; top right: environment window; bottom right: plots, help, and directories.\n\n\nIn RStudio, the top left window is always going to be our coding window. This is where we will type all of our code and create our documents. In the bottom left we will see R executing the code. This will show what the computer is “thinking” and will help us spot any potential issues. The top right window is the “environment”, which shows what variables and datasets are stored within the computers’ memory. (It can also show some other things, but we aren’t concerned with that at this point). The bottom right window is the “display” window. This is where plots and help windows will appear if they don’t appear in the document (top left) window itself.\nNow, we will create our first R document!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#setup-1",
    "href": "intro_to_r.html#setup-1",
    "title": "1  Intro to R",
    "section": "3.1 Setup",
    "text": "3.1 Setup\nIn this class, we will be creating assignments in what is called RMarkdown. This is a rich-text version of R that allows us to create documents with the code embedded. In RStudio, click the “+” button in the far top left to open the New Document menu. Scroll down this list and click on R Markdown.\nA screen such as this will appear:\n\n\n\nA new file window for an RMarkdown file.\n\n\nAfter entering a title and your name and selecting document in the left hand menu, click OK.\n\n\n\nAn example of a markdown script.\n\n\nIn the image above, we can see what a “default” RMarkdown script looks like after creating the file. At the top of the document, between all of the dashes, we have the yaml header that tells R what kind of document will be created, who the author is, and tells it to use today’s date. In this class, we will be saving documents as html as they are the easiest documents to create and save. These documents will include all of your code, text, and even any plots you may create!\nPlain text in the document will be rendered as plain text in the document. (I.e., whatever you type normally will become “normal text” in the finished document). Lines preceded with # will become headers, with ## being a second level header and ### being a third level header, etc. Words can also be made italic by putting an asterisk on each side of the word (*italic*) and bold by putting two asterisks on each side (**bold**). URLs are also supported, with &lt;&gt; on each side of a URL making it clickable, and words being hyperlinked by typing [words to show](target URL).\nWe also have code “chunks” that are shown above. A code chunk can be manually typed out or inserted by pressing CTRL + ALT + I (Windows, Linux) or COMMAND + OPTION + I (Mac). Everything inside a “code chunk” will be read as R code and executed as such. Note that you can have additional commands in the R chunks, but we won’t cover that for now.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#using-code-chunks",
    "href": "intro_to_r.html#using-code-chunks",
    "title": "1  Intro to R",
    "section": "3.2 Using code chunks",
    "text": "3.2 Using code chunks\nIn your computer, erase all information except for the yaml header between the dashes on your computer. Save your file in a folder where you want your assignment to be located. It is important you do this step up front as the computer will sometimes save in random places if you don’t specify a file location at the beginning. Don’t forget to save your work frequently!\n\n\n\nText to type in your Rmarkdown document.\n\n\nAfter typing this into the document, hit knit near the top of the upper left window. R will now create an HTML document that should look like this:\n\n\n\nThe output from the above code knitted into a document.\n\n\nWe can see now that the HTML document has the title of the document, the author’s name, the date on which the code was run, and a greyed-out box with color coded R code followed by the output. Let’s try something a little more complex. Create a new code chunk and type the following:\n\nx &lt;- 1:10\n\nThis will create a variable in R, x, that is sequentially each whole number between 1 and 10. We can see this by highlighting or typing only the letter x and running that line of code by clicking CTRL + ENTER (Windows / Linux) or COMMAND + ENTER (Mac).\n\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nIf you look at the top right window, you will also see the value x in the environment defined as int [1:10] 1 2 3 4 5 6 7 8 9 10. This indicates that x is integer data spanning ten positions numbered 1 to 10. Since the vector is small, it displays every number in the sequence.\n\n\n\nRStudio environment window showing saved objects. These are in the computer’s memory.\n\n\nLet’s create another vector y that is the squared values of x, such that \\(y=x^2\\). We can raise values to an exponent by using ^.\n\ny &lt;- x^2\ny\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nNow we have the value y in the environment that is the square of the values of x. This is a numeric vector of 10 values numbered 1 to 10 where each value corresponds to a square of the x value. We can raise things to any value however, including \\(x^x\\)!\n\nx^x\n\n [1]           1           4          27         256        3125       46656\n [7]      823543    16777216   387420489 10000000000\n\n\nAs we can see, since I didn’t “store” this value as a variable in R using &lt;-, the value is not in the environment.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#plotting",
    "href": "intro_to_r.html#plotting",
    "title": "1  Intro to R",
    "section": "3.3 Plotting",
    "text": "3.3 Plotting\nNow, let’s try creating a plot. This is easy in R, as we just use the command plot.\n\nplot(x = x, y = y)\n\n\n\n\n\n\n\n\nBy specifying the y and x components in plot, we can quickly generate a point plot. We can alter the visual parameters of this plot using a few different commands. I will outline these below with inline notes. Inline notes in the code can be made by using a # symbol before them, which basically tells R to ignore everything after the #. For example:\n\nprint(\"Test\")\n\n[1] \"Test\"\n\n# print(\"Test 2\")\n\nThis prints the word Test, but doesn’t print Test 2.\nNow let’s make the plot with some new visual parameters.\n\nplot(x = x, # specify x values\n     y = y, # specify y values\n     ylab = \"Y Values\", # specify Y label\n     xlab = \"X Values\", # specify X label\n     main = \"Plot Title\", # specify main title\n     pch = 19, # adjust point style\n     col = \"red\") # make points red",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#tab-complete",
    "href": "intro_to_r.html#tab-complete",
    "title": "1  Intro to R",
    "section": "3.4 Tab complete",
    "text": "3.4 Tab complete\nRStudio allows for “tab-completing” while typing code. Tab-completing is a way of typing the first part of a command, variable name, or file name and hitting “tab” to show all options with that spelling. You should use tab completing because it:\n\nreduces spelling mistakes\nreduces filepath mistakes\nincreases the speed at which you code\nprovides help with specific functions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#help",
    "href": "intro_to_r.html#help",
    "title": "1  Intro to R",
    "section": "3.5 Help",
    "text": "3.5 Help\nAt any point in R, you can look up “help” for a specific function by typing ?functionname. Try this on your computer with the following:\n\n?mean",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#downloading-data",
    "href": "intro_to_r.html#downloading-data",
    "title": "1  Intro to R",
    "section": "4.1 Downloading data",
    "text": "4.1 Downloading data\nNow, we need to download our first data set. These datasets are stored on GitHub. We are going to be looking at data from Dr. Cooper’s dissertation concerning Afrotropical bird distributions (Cooper 2021). This website is in the data folder on this websites’ GitHub page, accessible here.\n\n# first, declare filepath\n# I will try to give you the filepath for each assignment\n# if not, check the URL pattern for the file\n\n# create\nranges.url &lt;- curl(\"https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/lacustrine_range_size.csv\")\n# read comma separated file (csv) into R memory\nranges &lt;- read_csv(ranges.url)\n\nRows: 12 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): species\ndbl (9): combined_current_km2, consensus_km2, bioclim_current_km2, 2050_comb...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAlternatively, we can use the operator %&gt;% to simplify this process. %&gt;% means “take whatever you got from the previous step and pipe it into the next step”. So, the following does the exact same thing:\n\nranges &lt;- curl(\"https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/lacustrine_range_size.csv\") %&gt;%\n  read_csv()\n\nRows: 12 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): species\ndbl (9): combined_current_km2, consensus_km2, bioclim_current_km2, 2050_comb...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nUsing the %&gt;% is preferred as you can better set up a workflow and because it more closely mimics other coding languages, such as bash.\nLet’s view the data to see if it worked. We can use the command head to view the first few rows:\n\nhead(ranges)\n\n# A tibble: 6 × 10\n  species                combined_current_km2 consensus_km2 bioclim_current_km2\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;               &lt;dbl&gt;\n1 Batis_diops                          25209.         6694.              19241.\n2 Chamaetylas_poliophrys               68171.         1106.              68158.\n3 Cinnyris_regius                      60939.        13305.              53627.\n4 Cossypha_archeri                     27021.         6409.              11798.\n5 Cyanomitra_alinae                    78680.        34320.              63381.\n6 Graueria_vittata                      8770.          861.               8301.\n# ℹ 6 more variables: `2050_combined_km2` &lt;dbl&gt;, `2050_consensus_km2` &lt;dbl&gt;,\n#   `2070_combined_km2` &lt;dbl&gt;, `2070_consensus_km2` &lt;dbl&gt;,\n#   alltime_consensus_km2 &lt;dbl&gt;, past_stable_km2 &lt;dbl&gt;\n\n\nWe can perform a lot of summary statistics in R. Some of these we can view for multiple columns at once using summary.\n\nsummary(ranges)\n\n   species          combined_current_km2 consensus_km2     bioclim_current_km2\n Length:12          Min.   :  8770       Min.   :  861.3   Min.   :  3749     \n Class :character   1st Qu.: 24800       1st Qu.: 4186.2   1st Qu.: 10924     \n Mode  :character   Median : 43654       Median : 7778.1   Median : 31455     \n                    Mean   : 68052       Mean   :18161.8   Mean   : 42457     \n                    3rd Qu.: 70798       3rd Qu.:18558.7   3rd Qu.: 62835     \n                    Max.   :232377       Max.   :79306.6   Max.   :148753     \n 2050_combined_km2 2050_consensus_km2 2070_combined_km2  2070_consensus_km2\n Min.   :  1832    Min.   :    0.0    Min.   :   550.3   Min.   :    0.0   \n 1st Qu.:  6562    1st Qu.:  589.5    1st Qu.:  6583.8   1st Qu.:  311.4   \n Median : 26057    Median : 6821.9    Median : 24281.7   Median : 2714.6   \n Mean   : 33247    Mean   :14418.4    Mean   : 31811.0   Mean   : 8250.5   \n 3rd Qu.: 40460    3rd Qu.:18577.1    3rd Qu.: 38468.9   3rd Qu.:10034.4   \n Max.   :132487    Max.   :79236.2    Max.   :129591.0   Max.   :53291.8   \n alltime_consensus_km2 past_stable_km2 \n Min.   :    0.0       Min.   :   0.0  \n 1st Qu.:  790.9       1st Qu.:   0.0  \n Median : 8216.8       Median :   0.0  \n Mean   :15723.3       Mean   : 127.3  \n 3rd Qu.:19675.0       3rd Qu.:   0.0  \n Max.   :82310.5       Max.   :1434.8  \n\n\nAs seen above, we now have information for the following statistics for each variable:\n\nMin = minimum\n1st Qu. = 1st quartile\nMedian = middle of the dataset\nMean = average of the dataset\n3rd Qu. = 3rd quartile\nMax. = maximum\n\nWe can also calculate some of these statistics manually to see if we are doing everything correctly. It is easiest to do this by using predefined functions in R (code others have written to perform a particular task) or to create our own functions in R. We will do both to determine the average of combined_current_km2.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "intro_to_r.html#subsetting-data",
    "href": "intro_to_r.html#subsetting-data",
    "title": "1  Intro to R",
    "section": "4.2 Subsetting data",
    "text": "4.2 Subsetting data\nFirst, we need to select only the column of interest. In R, we have two ways of subsetting data to get a particular column.\n\nvar[rows,cols] is a way to look at a particular object (var in this case) and choose a specific combination of row number and column number (col). This is great if you know a specific index, but it is better to use a specific name.\nvar[rows,\"cols\"] is a way to do the above but by using a specific column name, like combined_current_km2.\nvar$colname is a way to call the specific column name directly from the dataset.\n\n\n# using R functions\n\nranges$combined_current_km2\n\n [1]  25209.4  68171.2  60939.2  27021.3  78679.9   8769.9 232377.2  17401.4\n [9]  51853.5  35455.1  23570.3 187179.1\n\n\nAs shown above, calling the specific column name with $ allows us to see only the data of interest. We can also save these data as an object.\n\ncurrent_combined &lt;- ranges$combined_current_km2\n\ncurrent_combined\n\n [1]  25209.4  68171.2  60939.2  27021.3  78679.9   8769.9 232377.2  17401.4\n [9]  51853.5  35455.1  23570.3 187179.1\n\n\nNow that we have it as an object, specifically a numeric vector, we can perform whatever math operations we need to on the dataset.\n\nmean(current_combined)\n\n[1] 68052.29\n\n\nHere, we can see the mean for the entire dataset. However, we should always round values to the same number of decimal points as the original data. We can do this with round.\n\nround(mean(current_combined),1) # round mean to one decimal\n\n[1] 68052.3\n\n\nNote that the above has a nested set of commands. We can write this exact same thing as follows:\n\n# pipe mean through round\nmean(current_combined) %&gt;%\n  round(1)\n\n[1] 68052.3\n\n\nUse the method that is easiest for you to follow!\nWe can also calculate the mean manually. The mean is \\(\\frac{\\sum_{i=1}^nx}{n}\\), or the sum of all the values within a vector divided by the number of values in that vector.\n\n# create function\n# use curly brackets to denote function\n# our data goes in place of \"x\" when finally run\nour_mean &lt;- function(x){\n  sum_x &lt;- sum(x) # sum all values in vector\n  n &lt;- length(x) # get length of vector\n  xbar &lt;- sum_x/n # calcualte mean\n  return(xbar) # return the value outside the function\n}\n\nLet’s try it.\n\nour_mean(ranges$combined_current_km2)\n\n[1] 68052.29\n\n\nAs we can see, it works just the same as mean! We can round this as well.\n\nour_mean(ranges$combined_current_km2) %&gt;%\n  round(1)\n\n[1] 68052.3",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to *R*</span>"
    ]
  },
  {
    "objectID": "descriptive_stats.html",
    "href": "descriptive_stats.html",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "2.1 Purposes of descriptive statistics\nDescriptive statistics enable researchers to quickly and easily examine the “behavior” of their datasets, identifying potential errors and allowing them to observe particular trends that may be worth further analysis. Here, we will cover how to calculate descriptive statistics for multiple different datasets, culminating in an assignment covering these topics.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_stats.html#preparing-r",
    "href": "descriptive_stats.html#preparing-r",
    "title": "2  Descriptive Statistics",
    "section": "2.2 Preparing R",
    "text": "2.2 Preparing R\nAs with every week, we will need to load our relevant packages first. This week, we are using the following:\n\n# allows for internet downloading\nlibrary(curl)\n\nUsing libcurl 8.7.1 with LibreSSL/3.3.6\n\n# enables data management tools\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::parse_date() masks curl::parse_date()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_stats.html#downloading-the-data",
    "href": "descriptive_stats.html#downloading-the-data",
    "title": "2  Descriptive Statistics",
    "section": "2.3 Downloading the data",
    "text": "2.3 Downloading the data\nFor the example this week, we will be using the starbucks dataset, describing the number of drinks purchased during particular time periods during the day.\n\nstarbucks &lt;- curl(\"https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/starbucks.csv\") %&gt;%\n  read_csv()\n\nRows: 9 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Hour\ndbl (1): Frap_Num\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_stats.html#descriptive-statistics",
    "href": "descriptive_stats.html#descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "2.4 Descriptive statistics",
    "text": "2.4 Descriptive statistics\nDescriptive statistics are statistics that help us understand the shape and nature of the data on hand. These include really common metrics such as mean, median, and mode, as well as more nuanced metrics like quartiles that help us understand if there is any skew in the dataset. (Skew refers to a bias in the data, where more data points lie on one side of the distribution and there is a long tail of data in the other direction).\n\n\n\nExamples of skew compared to a symmetrical, non-skewed distribution. Source: machinelearningparatodos.com\n\n\nNote above that the relative position of the mean, median, and mode can be indicative of skew. Please also note that these values will rarely be exactly equal “in the real world”, and thus you need to weigh differences against the entire dataset when assessing skew. There is a lot of nuance like this in statistics; it is not always an “exact” science, but sometimes involves judgment calls and assessments based on what you observe in the data.\nUsing the starbucks dataset, we can look at some of these descriptive statistics to understand what is going on.\n\n2.4.1 Notation\nAs a quick reminder, we use Greek lettering for populations and Roman lettering for samples. For example:\n\n\\(\\sigma\\) is a population, but \\(s\\) is a sample (both these variables refer to standard deviation).\n\\(\\mu\\) is a population, but \\(\\bar{x}\\) is a sample (both of these variables refer to the mean).\n\n\n\n2.4.2 Mean\nThe mean is the “average” value within a set of data, specifically, the sum of all values divided by the length of those values: \\(\\frac{\\sum_{i=1}^nx}{n}\\).\n\nhead(starbucks)\n\n# A tibble: 6 × 2\n  Hour      Frap_Num\n  &lt;chr&gt;        &lt;dbl&gt;\n1 0600-0659        2\n2 0700-0759        3\n3 0800-0859        2\n4 0900-0959        4\n5 1000-1059        8\n6 1100-1159        7\n\n\nHere, we are specifically interested in the number of frappuccinos.\n\n# get vector of frappuccino number\nfraps &lt;- starbucks$Frap_Num\n\n# get mean of vector\nmean(fraps)\n\n[1] 6.222222\n\n\nNote that the above should be rounded to a whole number, since we were given the data in whole numbers!\n\nmean(fraps) %&gt;%\n  round(0)\n\n[1] 6\n\n\nWe already covered calculating the average manually in our previous tutorial, but we can do that here as well:\n\n# sum values\n# divide by n, length of vector\n# round to 0 places\nround(sum(fraps)/length(fraps),0)\n\n[1] 6\n\n\n\n\n2.4.3 Range\nThe range is the difference between the largest and smallest units in a dataset. We can use the commands min and max to calculate this.\n\nmax(fraps) - min(fraps)\n\n[1] 13\n\n\nThe range of our dataset is 13.\n\n\n2.4.4 Median\nThe median is also known as the 50th percentile, and is the midpoint of the data when ordered from least to greatest. If there are an even number of data points, then it is the average point between the two center points. For odd data, this is the \\(\\frac{n+1}{2}\\)th observation. For even data, since we need to take an average, this is the \\(\\frac{\\frac{n}{2}+(\\frac{n}{2}+1)}{2}\\). You should be able to do these by hand and by using a program.\n\nmedian(fraps)\n\n[1] 4\n\n\nNow, to calculate by hand:\n\nlength(fraps)\n\n[1] 9\n\n\nWe have an odd length.\n\n# order gets the order\norder(fraps)\n\n[1] 1 3 7 2 4 6 5 9 8\n\n\n\n# [] tells R which elements to put where\nfrap_order &lt;- fraps[order(fraps)]\n\nfrap_order\n\n[1]  2  2  2  3  4  7  8 13 15\n\n\n\n# always use parentheses\n# make sure the math maths right!\n(length(frap_order)+1)/2\n\n[1] 5\n\n\nWhich is the fifth element in the vector?\n\nfrap_order[5]\n\n[1] 4\n\n\nNow let’s try it for an even numbers.\n\n# remove first element\neven_fraps &lt;- fraps[-1]\n\neven_fraps_order &lt;- even_fraps[order(even_fraps)]\n\neven_fraps_order\n\n[1]  2  2  3  4  7  8 13 15\n\n\n\nmedian(even_fraps)\n\n[1] 5.5\n\n\nNow, by hand: \\(\\frac{\\frac{n}{2}+(\\frac{n}{2}+1)}{2}\\).\n\nn &lt;- length(even_fraps_order)\n\n# get n/2 position from vector\nm1 &lt;- even_fraps_order[n/2]\n# get n/2+1 position\nm2 &lt;- even_fraps_order[(n/2)+1]\n\n# add these values, divide by two for \"midpoint\"\nmed &lt;- (m1+m2)/2\n\nmed\n\n[1] 5.5\n\n\nAs we can see, these values are equal!\n\n\n2.4.5 Other quartiles and quantiles\nWe also use the 25th percentile and the 75th percentile to understand data distributions. These are calculated similar to the above, but the bottom quartile is only \\(\\frac{1}{4}\\) of the way between values and the 75th quartile is \\(\\frac{3}{4}\\) of the way between values. We can use the R function quantile to calculate these.\n\nquantile(frap_order)\n\n  0%  25%  50%  75% 100% \n   2    2    4    8   15 \n\n\nWe can specify a quantile as well:\n\nquantile(frap_order, 0.75)\n\n75% \n  8 \n\n\nWe can also calculate these metrics by hand. Let’s do it for the even dataset, since this is more difficult.\n\nquantile(even_fraps_order)\n\n   0%   25%   50%   75%  100% \n 2.00  2.75  5.50  9.25 15.00 \n\n\nNote that the 25th and 75th percentiles are also between two different values. These can be calculated as a quarter and three-quarters of the way between their respective values.\n\n# 75th percentile\n\nn &lt;- length(even_fraps_order)\n\n# get position\np &lt;- 0.75*(n+1)\n\n# get lower value\n# round down\nm1 &lt;- even_fraps_order[trunc(p)]\n\n# get upper value\n# round up\nm2 &lt;- even_fraps_order[ceiling(p)]\n\n# position between\n# fractional portion of rank\nfrac &lt;- p-trunc(p)\n\n# calculate the offset from lowest value\nval &lt;- (m2 - m1)*frac\n\n# get value\nm1 + val\n\n[1] 11.75\n\n\nWait… why does our value differ?\nR, by default, calculates quantiles using what is called Type 7, in which the quantiles are calculated by \\(p_k = \\frac{k-1}{n-1}\\), where \\(n\\) is the length of the vector and \\(k\\) refers to the quantile being used. However, in our book and in this class, we use Type 6 interpretation - \\(p_k = \\frac{k}{n + 1}\\). Let’s try using Type 6:\n\nquantile(even_fraps_order, type = 6)\n\n   0%   25%   50%   75%  100% \n 2.00  2.25  5.50 11.75 15.00 \n\n\nNow we have the same answer as we calculated by hand!\nThis is a classic example of how things in R (and in statistics in general!) can depend on interpretation and are not always “hard and fast” rules.\nIn this class, we will be using Type 6 interpretation for the quantiles - you will have to specify this in the quantile function EVERY TIME! If you do not specify Type 6, you will get the questions incorrect and you will get answers that do not agree with the book, with Excel, or what you calculate by hand.\n\n\n2.4.6 Mode\nThere is no default method for finding the mode in R. However, websites like Statology provide wraparound functions.\n\n# Statology function\n# define function to calculate mode\nfind_mode &lt;- function(x) {\n  # get unique values from vector\n  u &lt;- unique(x)\n  # count number of occurrences for each value\n  tab &lt;- tabulate(match(x, u))\n  # return the value with the highest count\n  u[tab == max(tab)]\n}\n\nfind_mode(fraps)\n\n[1] 2\n\n\nWe can also do this by hand, by counting the number of occurrences of each value. This can be done in a stepwise fashion using commands in the above function.\n\n# unique counts\nu &lt;- unique(fraps)\nu\n\n[1]  2  3  4  8  7 15 13\n\n\n\n# which elements match\nmatch(fraps,u)\n\n[1] 1 2 1 3 4 5 1 6 7\n\n\n\n# count them\ntab &lt;- match(fraps,u) %&gt;%\n  tabulate()\n\ntab\n\n[1] 3 1 1 1 1 1 1\n\n\nGet the highest value.\n\nu[tab==max(tab)]\n\n[1] 2\n\n\nNotice this uses ==. This is a logical argument that means “is equal to” or “is the same as”. For example:\n\n2 == 2\n\n[1] TRUE\n\n\nThese values are the same, so TRUE is returned.\n\n2 == 3\n\n[1] FALSE\n\n\nThese values are unequal, so FALSE is returned. R will read TRUE as 1 and FALSE as ZERO, such that:\n\nsum(2==2)\n\n[1] 1\n\n\nand\n\nsum(2==3)\n\n[1] 0\n\n\nThis allows you to find how many arguments match your condition quickly, and even allows you to subset based on these indices as well. Keep in mind you can use greater than &lt;, less than &gt;, greater than or equal to &lt;=, less than or equal to &gt;=, is equal to ==, and is not equal to != to identify numerical relationships. Other logical arguments include:\n\n&: both conditions must be TRUE to match (e.g., c(10,20) & c(20,10)). Try the following as well: fraps &lt; 10 & fraps &gt; 3.\n&&: and, but works with single elements and allows for better parsing. Often used with if. E.g., fraps &lt; 10 && fraps &gt; 3. This will not work on our multi-element frap vector.\n|: or, saying at least one condition must be true. Try: fraps &gt; 10 | fraps &lt; 3.\n||: or, but for a single element, like && above.\n!: not, so “not equal to” would be !=.\n\n\n\n2.4.7 Variance\nWhen we are dealing with datasets, the variance is a measure of the total spread of the data. The variance is calculated using the following:\\[\\sigma^2=\\frac{\\sum (x_i-\\bar{x})^2}{n-1}\\]\nEssentially, this means that for every value of \\(x\\), we are finding the difference between that value and the mean and squaring it, summing all of these quared differences, and dividing them by the number of samples in the dataset minus one. Let’s do this for the frappuccino dataset.\n\nfrap_order\n\n[1]  2  2  2  3  4  7  8 13 15\n\n\nNow to find the differences.\n\ndiffs &lt;- frap_order - mean(frap_order)\n\ndiffs\n\n[1] -4.2222222 -4.2222222 -4.2222222 -3.2222222 -2.2222222  0.7777778  1.7777778\n[8]  6.7777778  8.7777778\n\n\nNote that R is calculating the same thing for the entire vector! Since these are differences from the mean, they should sum to zero.\n\nsum(diffs)\n\n[1] 3.552714e-15\n\n\nThis is not quite zero due to rounding error, but is essentially zero as it is 0.0000000000000036.\n\n# square differences\ndiffs_sq &lt;- diffs^2\n\ndiffs_sq\n\n[1] 17.8271605 17.8271605 17.8271605 10.3827160  4.9382716  0.6049383  3.1604938\n[8] 45.9382716 77.0493827\n\n\nNow we have the squared differences. We need to sum these and divide by \\(n-1\\).\n\nn &lt;- length(frap_order)\n\nvar_frap &lt;- sum(diffs_sq)/(n-1)\n\nvar_frap\n\n[1] 24.44444\n\n\nLet’s check this against the built-in variance function in R.\n\nvar(frap_order)\n\n[1] 24.44444\n\n\nThey are identical! We can check this using a logical argument.\n\nvar_frap == var(frap_order)\n\n[1] TRUE\n\n\nSeeing as this is TRUE, we calculated it correctly.\n\n\n2.4.8 Standard deviation\nAnother common measurement of spread is the standard deviation (\\(\\sigma\\)). As you remember from class (or may have guessed from the notation on this site), the standard deviation is just the square root of the variance.\n\nsqrt(var_frap)\n\n[1] 4.944132\n\n\nWe can test this against the built in sd function in R:\n\nsqrt(var_frap) == sd(frap_order)\n\n[1] TRUE\n\n\nAs you can see, we calculated this correctly!\n\n\n2.4.9 Standard error\nThe standard error is used to help understand the spread of data and to help estimate the accuracy of our measurements for things like the mean. The standard error is calculated thusly:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nThere is not built in function for the standard error in excel, but we can write our own:\n\nse &lt;- function(x){\n  n &lt;- length(x) # calculate n\n  s &lt;- sd(x) # calculate standard deviation\n  se_val &lt;- s/sqrt(n)\n  return(se_val)\n}\n\nLet’s test this code.\n\nse(frap_order)\n\n[1] 1.648044\n\n\nOur code works! And we can see exactly how the standard error is calculate. We can also adjust this code as needed for different situations, like samples.\nRemember, the standard error is used to help reflect our confidence in a specific measurement (e.g., how certain we are of the mean, and what values we believe the mean falls between). We want our estimates to be as precise as possible with as little uncertainty as possible. Given this, does having more samples make our estimates more or less confident? Mathematically, what happens as our sample size increases?\n\n\n2.4.10 Coefficient of variation\nThe coefficient of variation, another measure of data spread and location, is calculated by the following:\n\\[\nCV = \\frac{\\sigma}{\\mu}\n\\]\nWe can write a function to calculate this in R as well.\n\ncv &lt;- function(x){\n  sigma &lt;- sd(x)\n  mu &lt;- mean(x)\n  val &lt;- sigma/mu\n  return(val)\n}\n\ncv(frap_order)\n\n[1] 0.7945927\n\n\nRemember that we will need to round values.\n\n\n2.4.11 Outliers\nOutliers are any values that are outside of the 1.5 times the interquartile range. We can calculate this for our example dataset as follows:\n\nlowquant &lt;- quantile(frap_order,0.25,type = 6) %&gt;% as.numeric()\n\nhiquant &lt;- quantile(frap_order,0.75,type = 6) %&gt;% as.numeric()\n\niqr &lt;- hiquant - lowquant\n\nlowbound &lt;- mean(frap_order) - (1.5*iqr)\nhibound &lt;- mean(frap_order) + (1.5*iqr)\n\n# low outliers?\n# select elements that match\n# identify using logical \"which\"\nfrap_order[which(frap_order &lt; lowbound)]\n\nnumeric(0)\n\n\n\n# high outliers?\n# select elements that match\n# identify using logical \"which\"\nfrap_order[which(frap_order &gt; hibound)]\n\nnumeric(0)\n\n\nWe have no outliers for this particular dataset.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_stats.html#homework-descriptive-statistics",
    "href": "descriptive_stats.html#homework-descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "2.5 Homework: Descriptive Statistics",
    "text": "2.5 Homework: Descriptive Statistics\nNow that we’ve covered these basic statistics, it’s your turn! For this week, you will be completing homework that involves methods from Chapter 4 in your book.\n\n2.5.1 Homework instructions\nPlease create an RMarkdown document that will render as an .html file. You will submit this file to show your coding and your work. Please refer to the Introduction to R for refreshers on how to create an .html document in RMarkdown. You will need to do the following for each of these datasets:\n\nmean\nmedian\nrange\ninterquartile range\nvariance\nstandard deviation\ncoefficient of variation\nstandard error\nwhether there are any “outliers”\n\nPlease show all of your work for full credit.\n\n\n2.5.2 Data for homework problems\nFor each question, calculate the mean, median, range, interquartile range, variance, standard deviation, coefficient of variation, standard error, and whether there are any “outliers”.\nPlease also write your own short response to the Synthesis question posed, which will involve thinking about the data and metrics you just analyzed.\n\n2.5.2.1 1: UNK Nebraskans\nEver year, the university keeps track of where students are from. The following are data on the number of students admitted to UNK from the state of Nebraska:\n\n# create dataset in R\nnebraskans &lt;- c(5056,5061,5276,5244,5209,\n                5262,5466,5606,5508,5540,5614)\n\nyears &lt;- 2023:2013\n\nnebraskans_years &lt;- cbind(years,nebraskans) %&gt;% \n  as.data.frame()\n\nnebraskans_years\n\n   years nebraskans\n1   2023       5056\n2   2022       5061\n3   2021       5276\n4   2020       5244\n5   2019       5209\n6   2018       5262\n7   2017       5466\n8   2016       5606\n9   2015       5508\n10  2014       5540\n11  2013       5614\n\n\nUsing these data, please calculate the mean, median, range, interquartile range, variance, standard deviation, coefficient of variation, standard error, and whether there are any “outliers” for the number of UNK students from Nebraska.\nSynthesis question: Do you think that there are any really anomalous years? Do you feel data are similar between years? Note we are not looking at trends through time but whether any years are outliers.\n\n\n2.5.2.2 2: Piracy in the Gulf of Guinea\nThe following is a dataset looking at oceanic conditions and other variables associated with pirate attacks within the region between 2010 and 2021 (Moura et al. 2023). Using these data, please calculate the mean, median, range, interquartile range, variance, standard deviation, coefficient of variation, standard error, and whether there are any “outliers” for distance from shore for each pirate attack (columns Distance_from_Coast).\n\nurl_file &lt;- curl(\"https://figshare.com/ndownloader/files/42314604\")\npirates &lt;- url_file %&gt;% read_csv()\n\nNew names:\nRows: 595 Columns: 40\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(18): Period, Season, African_Season, Coastal_State, Coastal_Zone, Navi... dbl\n(20): ...1, Unnamed: 0, Year, Month, Lat_D, Lon_D, Distance_from_Coast,... dttm\n(2): Date_Time, Date\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\nSynthesis question: Do you notice any patterns in distance from shore? What may be responsible for these patterns? Hint: Think about what piracy entails and also what other columns are available as other variables in the above dataset.\n\n\n2.5.2.3 3: Patient ages at presentation\nThe following is a dataset on skin sores in different communities in Australia and Oceania, specifically looking at the amount of time that passes between skin infections (Lydeamore et al. 2020a). This file includes multiple different datasets, and focuses on data from children in the first five years of their life, on househould visits, and on data collected during targeted studies (Lydeamore et al. 2020b).\n\nurl_file &lt;- curl(\"https://doi.org/10.1371/journal.pcbi.1007838.s006\")\n\nages &lt;- url_file %&gt;% read_csv()\n\nRows: 17150 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): dataset\ndbl (1): time_difference\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s see what this file is like real fast. We can use the command dim to see the rows and columns.\n\ndim(ages)\n\n[1] 17150     2\n\n\nAs you can see, this file has only two columns but 17,150 rows! For the column time_difference, please calculate the mean, median, range, interquartile range, variance, standard deviation, coefficient of variation, standard error, and whether there are any “outliers”.\nSynthesis question: Folks will often think about probabilities of events being “low but never zero”. What does that mean in the context of these data? What about these data make you feel like probabilities may decrease through time but never become zero?\n\n\n\n\nLydeamore, M. J., P. T. Campbell, D. J. Price, Y. Wu, A. J. Marcato, W. Cuningham, J. R. Carapetis, R. M. Andrews, M. I. McDonald, J. McVernon, S. Y. C. Tong, and J. M. McCaw (2020b). Patient ages at presentation. https://doi.org/10.1371/journal.pcbi.1007838.s006\n\n\nLydeamore, M. J., P. T. Campbell, D. J. Price, Y. Wu, A. J. Marcato, W. Cuningham, J. R. Carapetis, R. M. Andrews, M. I. McDonald, J. McVernon, S. Y. C. Tong, and J. M. McCaw (2020a). Estimation of the force of infection and infectious period of skin sores in remote Australian communities using interval-censored data. PLOS Computational Biology 16:e1007838.\n\n\nMoura, R., N. P. Santos, and A. Rocha (2023). Processed csv file of the piracy dataset. https://doi.org/10.6084/m9.figshare.24119643.v1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "visual.html",
    "href": "visual.html",
    "title": "3  Diagnosing data visually",
    "section": "",
    "text": "3.1 The importance of visual inspection\nInspecting data visually can give us a lot of information about whether data are normally distributed and about whether there are any major errors or issues with our dataset. It can also help us determine if data meet model assumptions, or if we need to use different tests more appropriate for our datasets.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "visual.html#sample-data-and-preparation",
    "href": "visual.html#sample-data-and-preparation",
    "title": "3  Diagnosing data visually",
    "section": "3.2 Sample data and preparation",
    "text": "3.2 Sample data and preparation\nFirst, we need to load our R libraries.\n\nlibrary(curl)\n\nUsing libcurl 8.7.1 with LibreSSL/3.3.6\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::parse_date() masks curl::parse_date()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNext, we can download our data sample.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "visual.html#histograms",
    "href": "visual.html#histograms",
    "title": "3  Diagnosing data visually",
    "section": "3.3 Histograms",
    "text": "3.3 Histograms\nA histogram is a frequency diagram that we can use to visually diagnose data and their distributions. We are going to examine a histogram using a random string of data. R can generate random (though, actually pseudorandom) strings of data on command, pulling them from different distributions. These distributions are pseudorandom because we can’t actually program R to be random, so it starts from a wide variety of pseudorandom points.\n\n# create random string from normal distribution\nx &lt;- rnorm(n = 1000, # 1000 values\n           mean = 0,\n           sd = 1)\n\nhist(x)\n\n\n\n\n\n\n\n\nWe can up the number of bins to see this better.\n\nhist(x,breaks = 100)\n\n\n\n\n\n\n\n\nThe number of bins can be somewhat arbitrary, but a value should be chosen based off of what illustrates the data well. R will auto-select a number of bins in some cases, but you can also select a number of bins. Some assignments will ask you to choose a specific number of bins as well.\n\n3.3.1 ggplot histograms\nWe can also use the program ggplot, part of the tidyverse, to create histograms.\n\n# ggplot requires data frames\nx2 &lt;- x %&gt;% as.data.frame()\ncolnames(x2) &lt;- \"x\"\n\nggplot(data = x2, aes(x = x)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nggplot is nice because we can also clean up this graph a little.\n\nggplot(x2,aes(x=x)) + geom_histogram() +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can also do a histogram of multiple values at once in R.\n\nx2$cat &lt;- \"x\"\n\ny &lt;- rnorm(n = 1000,\n           mean = 1,\n           sd = 1) %&gt;%\n  as.data.frame()\n\ncolnames(y) &lt;- \"x\"\ny$cat &lt;- \"y\"\n\nxy &lt;- rbind(x2,y)\n\nhead(xy)\n\n           x cat\n1  0.2295921   x\n2  0.7991511   x\n3 -0.4636711   x\n4  0.8833398   x\n5  0.2054237   x\n6  0.4082193   x\n\n\n\nggplot(xy,aes(x = x, fill = cat)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can also make this look a little nicer.\n\nggplot(xy, aes(x = x, colour = cat)) +\n  geom_histogram(fill = \"white\", alpha = 0.5, # transparency\n                 position = \"identity\") +\n  theme_classic()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can show these a little differently as well.\n\nggplot(xy, aes(x = x, fill = cat))+\n  geom_histogram(position = \"identity\", alpha = 0.5) +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThere are lots of other commands you can incorporate as well if you so choose; I recommend checking sites like this one.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "visual.html#skewness",
    "href": "visual.html#skewness",
    "title": "3  Diagnosing data visually",
    "section": "3.4 Skewness",
    "text": "3.4 Skewness\nSkew is a measure of how much a dataset “leans” to the positive or negative directions (i.e., to the “left” or to the “right”). To calculate skew, we are going to use the moments library.\n\n# don't forget to install if needed!\nlibrary(moments)\n\nskewness(x)\n\n[1] -0.05893947\n\n\nGenerally, a value between \\(-1\\) and \\(+1\\) for skewness is “acceptable” and not considered overly skewed. Positive values indicate “right” skew and negative values indicate a “left” skew. If something is too skewed, it may violate assumptions of normality and thus need non-parametric tests rather than our standard parametric tests - something we will cover later!\nLet’s look at a skewed dataset. We are going to artificially create a skewed dataset from our x vector.\n\n# create more positive values\nx3 &lt;- c(x,\n        x[which(x &gt; 0)]*2,\n        x[which(x &gt; 0)]*4,\n        x[which(x &gt; 0)]*8)\n\nhist(x3)\n\n\n\n\n\n\n\n\n\nskewness(x3)\n\n[1] 2.199013\n\n\nAs we can see, the above is a heavily skewed dataset with a positive (“right”) skew.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "visual.html#kurtosis",
    "href": "visual.html#kurtosis",
    "title": "3  Diagnosing data visually",
    "section": "3.5 Kurtosis",
    "text": "3.5 Kurtosis\nKurtosis refers to how sharp or shallow the peak of the distribution is (platykurtic vs. leptokurtic). Remember - platykyrtic are plateaukurtic, wide and broad like a plateau, and leptokurtic distributions are sharp. Intermediate distributions that are roughly normal are mesokurtic.\nMuch like skewness, kurtosis values of \\(&gt; 2\\) and \\(&lt; -2\\) are generally considered extreme, and thus not mesokurtic. This threshold can vary a bit based on source, but for this class, we will use a threshold of \\(\\pm 2\\) for both skewness and kurtosis.\nLet’s see the kurtosis of x. Note that when doing the equation, a normal distribution actually has a kurtosis of \\(3\\); thus, we are doing kurtosis \\(-3\\) to “zero” the distribution and make it comparable to skewness.\n\nhist(x)\n\n\n\n\n\n\n\n\n\n# non-zeroed\nkurtosis(x)\n\n[1] 3.122281\n\n\n\n# zeroed\nkurtosis(x)-3\n\n[1] 0.1222813\n\n\nAs expected, out values drawn from a normal distribution are not overly skewed. Let’s compare these to a more kurtic distribution:\n\nxk &lt;- x^3\n\nkurtosis(xk)-3\n\n[1] 33.58032\n\n\nWhat does this dataset look like?\n\nhist(xk,breaks = 100)\n\n\n\n\n\n\n\n\nAs we can see, this is a very leptokurtic distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "visual.html#homework-chapter-3",
    "href": "visual.html#homework-chapter-3",
    "title": "3  Diagnosing data visually",
    "section": "3.6 Homework: Chapter 3",
    "text": "3.6 Homework: Chapter 3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Diagnosing data visually</span>"
    ]
  },
  {
    "objectID": "normality.html",
    "href": "normality.html",
    "title": "4  Normality & hypothesis testing",
    "section": "",
    "text": "4.1 Normal distributions\nA standard normal distribution is a mathematical model that describes a commonly observed phenomenon in nature. When measuring many different kinds of datasets, the data being measured often becomes something that resembles a standard normal distribution. This distribution is described by the following equation:\n\\[f(x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^\\frac{(x-\\mu)^2}{2\\sigma^2}\\]\nThis equation is fairly well defined by the variance (\\(\\sigma^2\\)), the overall spread of the data, and by the standard deviation (\\(\\sigma\\)), which is defined by the square root of the variance.\nThe standard normal distribution is a density function, and we are interested in the “area under the curve” (AUC) to understand the relative probability of an event occurring. When looking at a normal distribution distribution, it is impossible to say the probability of a specific event occurring, but it is possible to state the probability of an event as extreme or more extreme than the event observed occurring. This is known as the \\(p\\) value.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normality & hypothesis testing</span>"
    ]
  },
  {
    "objectID": "normality.html#normal-distributions",
    "href": "normality.html#normal-distributions",
    "title": "4  Normality & hypothesis testing",
    "section": "",
    "text": "A standard normal distribution, illustrating the percentage of area found within each standard deviation away from the mean. By Ainali on Wikipedia; CC-BY-SA 3.0.\n\n\n\n\n4.1.1 Example in nature\nIn order to see an example of the normal distribution in nature, we are going to examine the BeeWalk survey database from the island of Great Britain (Comont 2020). We are not interested in the bee data at present, however, but in the climatic data from when the surveys were performed.\n\nbeewalk &lt;- curl(\"https://figshare.com/ndownloader/files/44726902\") %&gt;%\n  read_csv()\n\nRows: 306550 Columns: 49\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (30): Website.ID, Website.RecordKey, SiteName, Site.section, ViceCounty,...\ndbl (19): RecordKey, established, Precision, Transect.lat, Transect.long, tr...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote that this is another massive dataset - \\(306,550\\) rows of data!\nThe dataset has the following columns:\n\ncolnames(beewalk)\n\n [1] \"RecordKey\"            \"Website.ID\"           \"Website.RecordKey\"   \n [4] \"SiteName\"             \"Site.section\"         \"ViceCounty\"          \n [7] \"established\"          \"GridReference\"        \"Projection\"          \n[10] \"Precision\"            \"Transect.lat\"         \"Transect.long\"       \n[13] \"transect.OS1936.lat\"  \"Transect.OS1936.long\" \"transect_length\"     \n[16] \"section_length\"       \"section_grid_ref\"     \"H1\"                  \n[19] \"H2\"                   \"H3\"                   \"H4\"                  \n[22] \"habitat_description\"  \"L1\"                   \"L2\"                  \n[25] \"land_use_description\" \"start_time\"           \"end_time\"            \n[28] \"sunshine\"             \"wind_speed\"           \"temperature\"         \n[31] \"TaxonVersionKey\"      \"species\"              \"latin\"               \n[34] \"queens\"               \"workers\"              \"males\"               \n[37] \"unknown\"              \"Comment\"              \"transect_comment\"    \n[40] \"flower_visited\"       \"StartDate\"            \"EndDate\"             \n[43] \"DateType\"             \"Year\"                 \"Month\"               \n[46] \"Day\"                  \"Sensitive\"            \"Week\"                \n[49] \"TotalCount\"          \n\n\nWe are specifically interested in temperature to determine weather conditions at start. Let’s see what the mean of this variable is.\n\nmean(beewalk$temperature)\n\n[1] NA\n\n\nHmmm… we are getting an NA value, indicating that not every cell has data recorded. Let’s view summary.\n\nsummary(beewalk$temperature)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   16.00   19.00   18.65   21.00   35.00   16151 \n\n\nAs we can see, \\(16,151\\) rows do not have temperature recorded! We want to remove these rows, so we can remove NA values using na.omit.\n\nbeewalk$temperature %&gt;%\n  na.omit() %&gt;%\n  mean() %&gt;%\n  round(2) # don't forget to round!\n\n[1] 18.65\n\n\nNow we can record the mean.\nLet’s visualize these data using a histogram.\n\nhist(beewalk$temperature,breaks = 5)\n\n\n\n\n\n\n\n\nEven with only five breaks, we can see an interesting, normal-esque distribution in the data. Let’s refine the bin number.\n\nhist(beewalk$temperature,breaks = 40)\n\n\n\n\n\n\n\n\nWith forty breaks, the pattern becomes even more clear. Let’s see what a standard normal distribution around these data would look like.\n\n# save temperature vector without NA values\ntemps &lt;- beewalk$temperature %&gt;% na.omit()\n\nmu &lt;- mean(temps)\nt.sd &lt;- sd(temps)\n\n# sample random values\nnormal.temps &lt;- rnorm(length(temps), # sample same size vector\n                      mean = mu,\n                      sd = t.sd)\n\nhist(normal.temps, breaks = 40)\n\n\n\n\n\n\n\n\nAs we can see, our normal approximation of temperatures is not too dissimilar from the distribution of temperatures we actually see!\nLet’s see what kind of data we have for temperatures:\n\nlibrary(moments)\n\nskewness(temps)\n\n[1] 0.02393257\n\n\nData do not have any significant skew.\n\nkurtosis(temps)-3\n\n[1] 0.3179243\n\n\nData do not show any significant kurtosis.\n\n\n4.1.2 Effect of sampling\nOftentimes, we will see things approach the normal distribution as we collect more samples. We can model this by subsampling our temperature vector.\n\nsub.temps &lt;- sample(temps,\n                    size = 10,\n                    replace = FALSE)\n\nhist(sub.temps, main = \"10 samples\")\n\n\n\n\n\n\n\n\nWith only ten values sampled, we do not have much of a normal distribution. Let’s up this to \\(100\\) samples.\n\nsub.temps &lt;- sample(temps,\n                    size = 100,\n                    replace = FALSE)\n\nhist(sub.temps, main = \"100 samples\",breaks = 10)\n\n\n\n\n\n\n\n\nNow we are starting to see more of a normal distribution! Let’s increase this to \\(1000\\) temperatures.\n\nsub.temps &lt;- sample(temps,\n                    size = 1000,\n                    replace = FALSE)\n\nhist(sub.temps, main = \"1000 samples\", breaks = 40)\n\n\n\n\n\n\n\n\nNow the normal distribution is even more clear. As we can also see, the more we sample, the more we approach the true means and distribution of the actual dataset. Because of this, we can perform experiments and observations of small groups and subsamples and make inferences about the whole, given that most systems naturally approach statistical distributions like the normal!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normality & hypothesis testing</span>"
    ]
  },
  {
    "objectID": "normality.html#hypothesis-testing",
    "href": "normality.html#hypothesis-testing",
    "title": "4  Normality & hypothesis testing",
    "section": "4.2 Hypothesis testing",
    "text": "4.2 Hypothesis testing",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normality & hypothesis testing</span>"
    ]
  },
  {
    "objectID": "normality.html#homework-chapter-8",
    "href": "normality.html#homework-chapter-8",
    "title": "4  Normality & hypothesis testing",
    "section": "4.3 Homework: Chapter 8",
    "text": "4.3 Homework: Chapter 8\n\n\n\n\nComont, R. (2020). BeeWalk dataset 2008-23. https://doi.org/10.6084/m9.figshare.12280547.v4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normality & hypothesis testing</span>"
    ]
  },
  {
    "objectID": "exam2.html",
    "href": "exam2.html",
    "title": "5  Exam 2 practice",
    "section": "",
    "text": "5.1 Exam 2\nThe following is practice for Exam 2.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exam 2 practice</span>"
    ]
  },
  {
    "objectID": "probdist.html",
    "href": "probdist.html",
    "title": "6  Probability distributions",
    "section": "",
    "text": "6.1 Probability distributions",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "probdist.html#binomial-distribution",
    "href": "probdist.html#binomial-distribution",
    "title": "6  Probability distributions",
    "section": "6.2 Binomial distribution",
    "text": "6.2 Binomial distribution",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "probdist.html#poisson-distribution",
    "href": "probdist.html#poisson-distribution",
    "title": "6  Probability distributions",
    "section": "6.3 Poisson distribution",
    "text": "6.3 Poisson distribution",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "probdist.html#chi-square-distribution",
    "href": "probdist.html#chi-square-distribution",
    "title": "6  Probability distributions",
    "section": "6.4 Chi-square distribution",
    "text": "6.4 Chi-square distribution",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "probdist.html#fishers-exact-test",
    "href": "probdist.html#fishers-exact-test",
    "title": "6  Probability distributions",
    "section": "6.5 Fisher’s exact test",
    "text": "6.5 Fisher’s exact test",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "probdist.html#homework",
    "href": "probdist.html#homework",
    "title": "6  Probability distributions",
    "section": "6.6 Homework",
    "text": "6.6 Homework\n\n6.6.1 Chapter 5\n\n\n6.6.2 Chapter 7",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "7  Single population means testing",
    "section": "",
    "text": "7.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-distribution",
    "href": "ttest.html#t-distribution",
    "title": "7  Single population means testing",
    "section": "7.2 t-distribution",
    "text": "7.2 t-distribution",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-tests",
    "href": "ttest.html#t-tests",
    "title": "7  Single population means testing",
    "section": "7.3 t-tests",
    "text": "7.3 t-tests",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "ttest.html#wilcoxon-tests",
    "href": "ttest.html#wilcoxon-tests",
    "title": "7  Single population means testing",
    "section": "7.4 Wilcoxon tests",
    "text": "7.4 Wilcoxon tests",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "ttest.html#confidence-intervals",
    "href": "ttest.html#confidence-intervals",
    "title": "7  Single population means testing",
    "section": "7.5 Confidence intervals",
    "text": "7.5 Confidence intervals",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "ttest.html#homework-chapter-9",
    "href": "ttest.html#homework-chapter-9",
    "title": "7  Single population means testing",
    "section": "7.6 Homework: Chapter 9",
    "text": "7.6 Homework: Chapter 9",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Single population means testing</span>"
    ]
  },
  {
    "objectID": "two_ttest.html",
    "href": "two_ttest.html",
    "title": "8  Two sample tests",
    "section": "",
    "text": "8.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Two sample tests</span>"
    ]
  },
  {
    "objectID": "two_ttest.html#t-tests",
    "href": "two_ttest.html#t-tests",
    "title": "8  Two sample tests",
    "section": "8.2 t-tests",
    "text": "8.2 t-tests",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Two sample tests</span>"
    ]
  },
  {
    "objectID": "two_ttest.html#mann-whitney-u-tests",
    "href": "two_ttest.html#mann-whitney-u-tests",
    "title": "8  Two sample tests",
    "section": "8.3 Mann-Whitney U tests",
    "text": "8.3 Mann-Whitney U tests",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Two sample tests</span>"
    ]
  },
  {
    "objectID": "two_ttest.html#error",
    "href": "two_ttest.html#error",
    "title": "8  Two sample tests",
    "section": "8.4 Error",
    "text": "8.4 Error",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Two sample tests</span>"
    ]
  },
  {
    "objectID": "two_ttest.html#homework-chapter-10",
    "href": "two_ttest.html#homework-chapter-10",
    "title": "8  Two sample tests",
    "section": "8.5 Homework: Chapter 10",
    "text": "8.5 Homework: Chapter 10",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Two sample tests</span>"
    ]
  },
  {
    "objectID": "anova1.html",
    "href": "anova1.html",
    "title": "9  ANOVA: Part 1",
    "section": "",
    "text": "9.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ANOVA: Part 1</span>"
    ]
  },
  {
    "objectID": "anova1.html#anova-by-hand",
    "href": "anova1.html#anova-by-hand",
    "title": "9  ANOVA: Part 1",
    "section": "9.2 ANOVA: By hand",
    "text": "9.2 ANOVA: By hand",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ANOVA: Part 1</span>"
    ]
  },
  {
    "objectID": "anova1.html#anova-by-r",
    "href": "anova1.html#anova-by-r",
    "title": "9  ANOVA: Part 1",
    "section": "9.3 ANOVA: By R",
    "text": "9.3 ANOVA: By R",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ANOVA: Part 1</span>"
    ]
  },
  {
    "objectID": "anova1.html#kruskal-wallis-tests",
    "href": "anova1.html#kruskal-wallis-tests",
    "title": "9  ANOVA: Part 1",
    "section": "9.4 Kruskal-Wallis tests",
    "text": "9.4 Kruskal-Wallis tests",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ANOVA: Part 1</span>"
    ]
  },
  {
    "objectID": "anova1.html#homework-chapter-11",
    "href": "anova1.html#homework-chapter-11",
    "title": "9  ANOVA: Part 1",
    "section": "9.5 Homework: Chapter 11",
    "text": "9.5 Homework: Chapter 11",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ANOVA: Part 1</span>"
    ]
  },
  {
    "objectID": "anova2.html",
    "href": "anova2.html",
    "title": "10  ANOVA: Part 2",
    "section": "",
    "text": "10.1 Two-way ANOVA",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA: Part 2</span>"
    ]
  },
  {
    "objectID": "anova2.html#designs",
    "href": "anova2.html#designs",
    "title": "10  ANOVA: Part 2",
    "section": "10.2 Designs",
    "text": "10.2 Designs\n\n10.2.1 Randomized block design\n\n\n10.2.2 Repeated measures\n\n\n10.2.3 Factorial ANOVA",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA: Part 2</span>"
    ]
  },
  {
    "objectID": "anova2.html#friedmans-test",
    "href": "anova2.html#friedmans-test",
    "title": "10  ANOVA: Part 2",
    "section": "10.3 Friedman’s test",
    "text": "10.3 Friedman’s test",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA: Part 2</span>"
    ]
  },
  {
    "objectID": "anova2.html#homework-chapter-12",
    "href": "anova2.html#homework-chapter-12",
    "title": "10  ANOVA: Part 2",
    "section": "10.4 Homework: Chapter 12",
    "text": "10.4 Homework: Chapter 12",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA: Part 2</span>"
    ]
  },
  {
    "objectID": "cor_reg.html",
    "href": "cor_reg.html",
    "title": "11  Correlation & regression",
    "section": "",
    "text": "11.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation & regression</span>"
    ]
  },
  {
    "objectID": "cor_reg.html#correlation",
    "href": "cor_reg.html#correlation",
    "title": "11  Correlation & regression",
    "section": "11.2 Correlation",
    "text": "11.2 Correlation\n\n11.2.1 Pearson’s\n\n\n11.2.2 Spearman’s\n\n\n11.2.3 Other non-parametric methods",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation & regression</span>"
    ]
  },
  {
    "objectID": "cor_reg.html#correlation-1",
    "href": "cor_reg.html#correlation-1",
    "title": "11  Correlation & regression",
    "section": "11.3 Correlation",
    "text": "11.3 Correlation\n\n11.3.1 Parametric\n\n\n11.3.2 Non-parametric",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation & regression</span>"
    ]
  },
  {
    "objectID": "cor_reg.html#homework",
    "href": "cor_reg.html#homework",
    "title": "11  Correlation & regression",
    "section": "11.4 Homework",
    "text": "11.4 Homework\n\n11.4.1 Chapter 13\n\n\n11.4.2 Chapter 14",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation & regression</span>"
    ]
  },
  {
    "objectID": "final_exam.html",
    "href": "final_exam.html",
    "title": "12  Final exam & review",
    "section": "",
    "text": "12.1 Pick the test",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Final exam & review</span>"
    ]
  },
  {
    "objectID": "final_exam.html#final-review",
    "href": "final_exam.html#final-review",
    "title": "12  Final exam & review",
    "section": "12.2 Final review",
    "text": "12.2 Final review",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Final exam & review</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "13  Conclusions",
    "section": "",
    "text": "13.1 ᏙᏓᏓᎪᎲᎢ\nᏙᏓᏓᎪᎲᎢ (pronounced doh-dah-dah-go-huh-ee) is a traditional Cherokee farewell. It does not mean goodbye, but rather reflects a parting of ways until a group of folks meet again.\nI enjoyed getting to know all of you in class, and please feel free to reach out or stop by and say hi if you are ever passing through Kearney in the future or if you need help with something biology related.\nWishing you the best,\nDr. Cooper",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Conclusions</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Comont, R. (2020). BeeWalk dataset 2008-23.\nhttps://doi.org/10.6084/m9.figshare.12280547.v4\n\n\nCooper, J. C. (2021). Biogeographic and Ecologic\nDrivers of Avian Diversity.\n[Online.] Available at https://doi.org/10.6082/uchicago.3379.\n\n\nLydeamore, M. J., P. T. Campbell, D. J. Price, Y. Wu, A. J. Marcato, W.\nCuningham, J. R. Carapetis, R. M. Andrews, M. I. McDonald, J. McVernon,\nS. Y. C. Tong, and J. M. McCaw (2020a). Patient\nages at presentation. https://doi.org/10.1371/journal.pcbi.1007838.s006\n\n\nLydeamore, M. J., P. T. Campbell, D. J. Price, Y. Wu, A. J. Marcato, W.\nCuningham, J. R. Carapetis, R. M. Andrews, M. I. McDonald, J. McVernon,\nS. Y. C. Tong, and J. M. McCaw (2020b). Estimation of the\nforce of infection and infectious period of skin sores in remote\nAustralian communities using interval-censored data.\nPLOS Computational Biology 16:e1007838.\n\n\nMoura, R., N. P. Santos, and A. Rocha (2023). Processed csv file of the piracy dataset.\nhttps://doi.org/10.6084/m9.figshare.24119643.v1",
    "crumbs": [
      "References"
    ]
  }
]